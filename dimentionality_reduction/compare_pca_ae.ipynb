{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wrong-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasta2df import fasta_to_df, all_data_df_to_arange_df\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "N = 5\n",
    "BASE = [\"A\", \"T\", \"G\", \"C\"]\n",
    "N_BASE = [\"\".join(i) for i in list(itertools.product(BASE, repeat=N))]\n",
    "\n",
    "JAPAN_HEADER_COLUMNS = [\"head\", \"ID\", \"date\"]\n",
    "ALL_DATA_HEADER_COLUMNS = [\"head\", \"id\", \"continent\", \"country\", \"city\", \"host\", \"clade_head\", \"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "historic-learning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "header, feature = fasta_to_df(\"all_data_odd_penta\", N, ALL_DATA_HEADER_COLUMNS, N_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlike-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_data_df_to_arange_df(header, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "finished-myrtle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAA</th>\n",
       "      <th>AAAAT</th>\n",
       "      <th>AAAAG</th>\n",
       "      <th>AAAAC</th>\n",
       "      <th>AAATA</th>\n",
       "      <th>AAATT</th>\n",
       "      <th>AAATG</th>\n",
       "      <th>AAATC</th>\n",
       "      <th>AAAGA</th>\n",
       "      <th>AAAGT</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>host</th>\n",
       "      <th>clade_head</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>clade</th>\n",
       "      <th>head2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789334</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>1.415344</td>\n",
       "      <td>1.350947</td>\n",
       "      <td>0.589727</td>\n",
       "      <td>1.157516</td>\n",
       "      <td>1.355789</td>\n",
       "      <td>0.787686</td>\n",
       "      <td>1.565456</td>\n",
       "      <td>1.136470</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Human</td>\n",
       "      <td>L_&gt;Wuhan/IVDC-HB-01/2019</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>L</td>\n",
       "      <td>Wuhan/IVDC-HB-01/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.789334</td>\n",
       "      <td>0.917161</td>\n",
       "      <td>1.415344</td>\n",
       "      <td>1.351440</td>\n",
       "      <td>0.589604</td>\n",
       "      <td>1.157033</td>\n",
       "      <td>1.355506</td>\n",
       "      <td>0.787809</td>\n",
       "      <td>1.565456</td>\n",
       "      <td>1.136233</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Human</td>\n",
       "      <td>L_&gt;Wuhan/IVDC-HB-04/2020</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>L</td>\n",
       "      <td>Wuhan/IVDC-HB-04/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788450</td>\n",
       "      <td>0.916530</td>\n",
       "      <td>1.414558</td>\n",
       "      <td>1.349736</td>\n",
       "      <td>0.589198</td>\n",
       "      <td>1.156737</td>\n",
       "      <td>1.355340</td>\n",
       "      <td>0.787157</td>\n",
       "      <td>1.564586</td>\n",
       "      <td>1.136093</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Human</td>\n",
       "      <td>L_&gt;Wuhan/IVDC-HB-05/2019</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>L</td>\n",
       "      <td>Wuhan/IVDC-HB-05/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.789777</td>\n",
       "      <td>0.917860</td>\n",
       "      <td>1.415496</td>\n",
       "      <td>1.351553</td>\n",
       "      <td>0.590053</td>\n",
       "      <td>1.158147</td>\n",
       "      <td>1.335984</td>\n",
       "      <td>0.788033</td>\n",
       "      <td>1.565624</td>\n",
       "      <td>1.136583</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Human</td>\n",
       "      <td>L_&gt;Wuhan/IPBCAMS-WH-01/2019</td>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>L</td>\n",
       "      <td>Wuhan/IPBCAMS-WH-01/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.789334</td>\n",
       "      <td>0.917352</td>\n",
       "      <td>1.415344</td>\n",
       "      <td>1.350947</td>\n",
       "      <td>0.589727</td>\n",
       "      <td>1.157516</td>\n",
       "      <td>1.355789</td>\n",
       "      <td>0.787686</td>\n",
       "      <td>1.565456</td>\n",
       "      <td>1.136470</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Human</td>\n",
       "      <td>L_&gt;Wuhan/WIV04/2019</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>L</td>\n",
       "      <td>Wuhan/WIV04/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130748</th>\n",
       "      <td>0.792666</td>\n",
       "      <td>0.919955</td>\n",
       "      <td>1.420330</td>\n",
       "      <td>1.359169</td>\n",
       "      <td>0.591400</td>\n",
       "      <td>1.159200</td>\n",
       "      <td>1.338710</td>\n",
       "      <td>0.791388</td>\n",
       "      <td>1.570971</td>\n",
       "      <td>1.138903</td>\n",
       "      <td>...</td>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>Human</td>\n",
       "      <td>GR_&gt;England/MILK-A7CA70/2020</td>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>GR</td>\n",
       "      <td>England/MILK-A7CA70/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130749</th>\n",
       "      <td>0.790441</td>\n",
       "      <td>0.917984</td>\n",
       "      <td>1.418595</td>\n",
       "      <td>1.378596</td>\n",
       "      <td>0.590133</td>\n",
       "      <td>1.181857</td>\n",
       "      <td>1.337966</td>\n",
       "      <td>0.768501</td>\n",
       "      <td>1.569052</td>\n",
       "      <td>1.158239</td>\n",
       "      <td>...</td>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>Human</td>\n",
       "      <td>GR_&gt;England/MILK-A7D541/2020</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>GR</td>\n",
       "      <td>England/MILK-A7D541/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130750</th>\n",
       "      <td>0.805264</td>\n",
       "      <td>0.945318</td>\n",
       "      <td>1.418637</td>\n",
       "      <td>1.333367</td>\n",
       "      <td>0.590824</td>\n",
       "      <td>1.171381</td>\n",
       "      <td>1.358370</td>\n",
       "      <td>0.811871</td>\n",
       "      <td>1.569098</td>\n",
       "      <td>1.138633</td>\n",
       "      <td>...</td>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>Human</td>\n",
       "      <td>G_&gt;England/MILK-A7DC6A/2020</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>G</td>\n",
       "      <td>England/MILK-A7DC6A/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130751</th>\n",
       "      <td>0.791775</td>\n",
       "      <td>0.918936</td>\n",
       "      <td>1.419295</td>\n",
       "      <td>1.358693</td>\n",
       "      <td>0.590744</td>\n",
       "      <td>1.157935</td>\n",
       "      <td>1.357723</td>\n",
       "      <td>0.812505</td>\n",
       "      <td>1.569826</td>\n",
       "      <td>1.138091</td>\n",
       "      <td>...</td>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>Human</td>\n",
       "      <td>GV_&gt;England/MILK-A7D14D/2020</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>GV</td>\n",
       "      <td>England/MILK-A7D14D/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130752</th>\n",
       "      <td>0.792220</td>\n",
       "      <td>0.919541</td>\n",
       "      <td>1.419448</td>\n",
       "      <td>1.359055</td>\n",
       "      <td>0.591134</td>\n",
       "      <td>1.158809</td>\n",
       "      <td>1.358000</td>\n",
       "      <td>0.791411</td>\n",
       "      <td>1.569996</td>\n",
       "      <td>1.138324</td>\n",
       "      <td>...</td>\n",
       "      <td>United_Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>Human</td>\n",
       "      <td>GV_&gt;England/MILK-A7D6E4/2020</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>GV</td>\n",
       "      <td>England/MILK-A7D6E4/2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130740 rows × 1037 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AAAAA     AAAAT     AAAAG     AAAAC     AAATA     AAATT     AAATG  \\\n",
       "0       0.789334  0.917352  1.415344  1.350947  0.589727  1.157516  1.355789   \n",
       "1       0.789334  0.917161  1.415344  1.351440  0.589604  1.157033  1.355506   \n",
       "2       0.788450  0.916530  1.414558  1.349736  0.589198  1.156737  1.355340   \n",
       "3       0.789777  0.917860  1.415496  1.351553  0.590053  1.158147  1.335984   \n",
       "4       0.789334  0.917352  1.415344  1.350947  0.589727  1.157516  1.355789   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "130748  0.792666  0.919955  1.420330  1.359169  0.591400  1.159200  1.338710   \n",
       "130749  0.790441  0.917984  1.418595  1.378596  0.590133  1.181857  1.337966   \n",
       "130750  0.805264  0.945318  1.418637  1.333367  0.590824  1.171381  1.358370   \n",
       "130751  0.791775  0.918936  1.419295  1.358693  0.590744  1.157935  1.357723   \n",
       "130752  0.792220  0.919541  1.419448  1.359055  0.591134  1.158809  1.358000   \n",
       "\n",
       "           AAATC     AAAGA     AAAGT  ...         country     city   host  \\\n",
       "0       0.787686  1.565456  1.136470  ...           China    Hubei  Human   \n",
       "1       0.787809  1.565456  1.136233  ...           China    Hubei  Human   \n",
       "2       0.787157  1.564586  1.136093  ...           China    Hubei  Human   \n",
       "3       0.788033  1.565624  1.136583  ...           China    Hubei  Human   \n",
       "4       0.787686  1.565456  1.136470  ...           China    Hubei  Human   \n",
       "...          ...       ...       ...  ...             ...      ...    ...   \n",
       "130748  0.791388  1.570971  1.138903  ...  United_Kingdom  England  Human   \n",
       "130749  0.768501  1.569052  1.158239  ...  United_Kingdom  England  Human   \n",
       "130750  0.811871  1.569098  1.138633  ...  United_Kingdom  England  Human   \n",
       "130751  0.812505  1.569826  1.138091  ...  United_Kingdom  England  Human   \n",
       "130752  0.791411  1.569996  1.138324  ...  United_Kingdom  England  Human   \n",
       "\n",
       "                          clade_head        date  year  month  day  clade  \\\n",
       "0           L_>Wuhan/IVDC-HB-01/2019  2019-12-30  2019     12   30      L   \n",
       "1           L_>Wuhan/IVDC-HB-04/2020  2020-01-01  2020     01   01      L   \n",
       "2           L_>Wuhan/IVDC-HB-05/2019  2019-12-30  2019     12   30      L   \n",
       "3        L_>Wuhan/IPBCAMS-WH-01/2019  2019-12-24  2019     12   24      L   \n",
       "4                L_>Wuhan/WIV04/2019  2019-12-30  2019     12   30      L   \n",
       "...                              ...         ...   ...    ...  ...    ...   \n",
       "130748  GR_>England/MILK-A7CA70/2020  2020-10-15  2020     10   15     GR   \n",
       "130749  GR_>England/MILK-A7D541/2020  2020-10-13  2020     10   13     GR   \n",
       "130750   G_>England/MILK-A7DC6A/2020  2020-10-13  2020     10   13      G   \n",
       "130751  GV_>England/MILK-A7D14D/2020  2020-10-13  2020     10   13     GV   \n",
       "130752  GV_>England/MILK-A7D6E4/2020  2020-10-13  2020     10   13     GV   \n",
       "\n",
       "                           head2  \n",
       "0          Wuhan/IVDC-HB-01/2019  \n",
       "1          Wuhan/IVDC-HB-04/2020  \n",
       "2          Wuhan/IVDC-HB-05/2019  \n",
       "3       Wuhan/IPBCAMS-WH-01/2019  \n",
       "4               Wuhan/WIV04/2019  \n",
       "...                          ...  \n",
       "130748  England/MILK-A7CA70/2020  \n",
       "130749  England/MILK-A7D541/2020  \n",
       "130750  England/MILK-A7DC6A/2020  \n",
       "130751  England/MILK-A7D14D/2020  \n",
       "130752  England/MILK-A7D6E4/2020  \n",
       "\n",
       "[130740 rows x 1037 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "allied-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:8.657644271850586[sec]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 主成分分析をします\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(data[N_BASE])\n",
    " \n",
    "# データセットを主成分に変換する\n",
    "transformed = pca.fit_transform(data[N_BASE])\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incorporate-tiger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130740, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "wicked-showcase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24383988,  0.27530975],\n",
       "       [-0.24444125,  0.27795642],\n",
       "       [-0.23808526,  0.29973193],\n",
       "       ...,\n",
       "       [-0.18704974, -0.0755207 ],\n",
       "       [-0.2041916 , -0.18359061],\n",
       "       [-0.19796559, -0.20507592]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fabulous-semester",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.9918 - val_loss: 0.9257\n",
      "Epoch 2/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.8728 - val_loss: 0.6430\n",
      "Epoch 3/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.6130 - val_loss: 0.5637\n",
      "Epoch 4/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5674 - val_loss: 0.5589\n",
      "Epoch 5/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5668 - val_loss: 0.5585\n",
      "Epoch 6/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5642 - val_loss: 0.5583\n",
      "Epoch 7/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5636 - val_loss: 0.5581\n",
      "Epoch 8/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5606 - val_loss: 0.5579\n",
      "Epoch 9/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5661 - val_loss: 0.5578\n",
      "Epoch 10/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5694 - val_loss: 0.5576\n",
      "Epoch 11/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5703 - val_loss: 0.5574\n",
      "Epoch 12/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5673 - val_loss: 0.5572\n",
      "Epoch 13/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5617 - val_loss: 0.5570\n",
      "Epoch 14/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5654 - val_loss: 0.5567\n",
      "Epoch 15/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5717 - val_loss: 0.5564\n",
      "Epoch 16/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5732 - val_loss: 0.5561\n",
      "Epoch 17/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5639 - val_loss: 0.5557\n",
      "Epoch 18/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5641 - val_loss: 0.5552\n",
      "Epoch 19/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5684 - val_loss: 0.5547\n",
      "Epoch 20/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5659 - val_loss: 0.5540\n",
      "Epoch 21/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5590 - val_loss: 0.5532\n",
      "Epoch 22/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5615 - val_loss: 0.5522\n",
      "Epoch 23/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5538 - val_loss: 0.5511\n",
      "Epoch 24/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5621 - val_loss: 0.5498\n",
      "Epoch 25/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5535 - val_loss: 0.5483\n",
      "Epoch 26/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5531 - val_loss: 0.5466\n",
      "Epoch 27/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5484 - val_loss: 0.5448\n",
      "Epoch 28/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5573 - val_loss: 0.5428\n",
      "Epoch 29/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5539 - val_loss: 0.5408\n",
      "Epoch 30/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5496 - val_loss: 0.5388\n",
      "Epoch 31/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5431 - val_loss: 0.5369\n",
      "Epoch 32/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5431 - val_loss: 0.5351\n",
      "Epoch 33/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5415 - val_loss: 0.5334\n",
      "Epoch 34/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5394 - val_loss: 0.5319\n",
      "Epoch 35/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5406 - val_loss: 0.5307\n",
      "Epoch 36/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5416 - val_loss: 0.5296\n",
      "Epoch 37/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5316 - val_loss: 0.5287\n",
      "Epoch 38/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5427 - val_loss: 0.5279\n",
      "Epoch 39/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5324 - val_loss: 0.5273\n",
      "Epoch 40/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5279 - val_loss: 0.5268\n",
      "Epoch 41/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5396 - val_loss: 0.5264\n",
      "Epoch 42/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5311 - val_loss: 0.5261\n",
      "Epoch 43/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5343 - val_loss: 0.5258\n",
      "Epoch 44/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5298 - val_loss: 0.5256\n",
      "Epoch 45/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5360 - val_loss: 0.5254\n",
      "Epoch 46/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5352 - val_loss: 0.5252\n",
      "Epoch 47/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.5251\n",
      "Epoch 48/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5292 - val_loss: 0.5250\n",
      "Epoch 49/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5290 - val_loss: 0.5249\n",
      "Epoch 50/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5329 - val_loss: 0.5248\n",
      "Epoch 51/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5294 - val_loss: 0.5247\n",
      "Epoch 52/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5280 - val_loss: 0.5246\n",
      "Epoch 53/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5314 - val_loss: 0.5246\n",
      "Epoch 54/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5345 - val_loss: 0.5245\n",
      "Epoch 55/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5307 - val_loss: 0.5245\n",
      "Epoch 56/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5299 - val_loss: 0.5244\n",
      "Epoch 57/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5300 - val_loss: 0.5244\n",
      "Epoch 58/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5257 - val_loss: 0.5243\n",
      "Epoch 59/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5315 - val_loss: 0.5243\n",
      "Epoch 60/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5287 - val_loss: 0.5243\n",
      "Epoch 61/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5276 - val_loss: 0.5242\n",
      "Epoch 62/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5236 - val_loss: 0.5242\n",
      "Epoch 63/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5377 - val_loss: 0.5242\n",
      "Epoch 64/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5249 - val_loss: 0.5242\n",
      "Epoch 65/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5255 - val_loss: 0.5241\n",
      "Epoch 66/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5320 - val_loss: 0.5241\n",
      "Epoch 67/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5243 - val_loss: 0.5241\n",
      "Epoch 68/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5309 - val_loss: 0.5240\n",
      "Epoch 69/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5306 - val_loss: 0.5240\n",
      "Epoch 70/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.5240\n",
      "Epoch 71/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5292 - val_loss: 0.5240\n",
      "Epoch 72/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5252 - val_loss: 0.5240\n",
      "Epoch 73/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5325 - val_loss: 0.5239\n",
      "Epoch 74/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5303 - val_loss: 0.5239\n",
      "Epoch 75/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5317 - val_loss: 0.5239\n",
      "Epoch 76/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5280 - val_loss: 0.5239\n",
      "Epoch 77/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5291 - val_loss: 0.5239\n",
      "Epoch 78/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5290 - val_loss: 0.5238\n",
      "Epoch 79/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5297 - val_loss: 0.5238\n",
      "Epoch 80/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5250 - val_loss: 0.5238\n",
      "Epoch 81/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5336 - val_loss: 0.5238\n",
      "Epoch 82/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5288 - val_loss: 0.5238\n",
      "Epoch 83/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5225 - val_loss: 0.5238\n",
      "Epoch 84/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5290 - val_loss: 0.5237\n",
      "Epoch 85/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5256 - val_loss: 0.5237\n",
      "Epoch 86/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5235 - val_loss: 0.5237\n",
      "Epoch 87/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5271 - val_loss: 0.5237\n",
      "Epoch 88/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.5237\n",
      "Epoch 89/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5310 - val_loss: 0.5237\n",
      "Epoch 90/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5291 - val_loss: 0.5237\n",
      "Epoch 91/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5324 - val_loss: 0.5237\n",
      "Epoch 92/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.5236\n",
      "Epoch 93/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.5236\n",
      "Epoch 94/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5269 - val_loss: 0.5236\n",
      "Epoch 95/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5288 - val_loss: 0.5236\n",
      "Epoch 96/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5270 - val_loss: 0.5236\n",
      "Epoch 97/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5262 - val_loss: 0.5236\n",
      "Epoch 98/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5304 - val_loss: 0.5236\n",
      "Epoch 99/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5294 - val_loss: 0.5236\n",
      "Epoch 100/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5285 - val_loss: 0.5236\n",
      "Epoch 101/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5285 - val_loss: 0.5235\n",
      "Epoch 102/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5267 - val_loss: 0.5235\n",
      "Epoch 103/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5289 - val_loss: 0.5235\n",
      "Epoch 104/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5290 - val_loss: 0.5235\n",
      "Epoch 105/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5289 - val_loss: 0.5235\n",
      "Epoch 106/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5254 - val_loss: 0.5235\n",
      "Epoch 107/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5322 - val_loss: 0.5235\n",
      "Epoch 108/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.5235\n",
      "Epoch 109/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5270 - val_loss: 0.5235\n",
      "Epoch 110/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5246 - val_loss: 0.5235\n",
      "Epoch 111/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5324 - val_loss: 0.5235\n",
      "Epoch 112/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5314 - val_loss: 0.5234\n",
      "Epoch 113/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5308 - val_loss: 0.5234\n",
      "Epoch 114/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5290 - val_loss: 0.5234\n",
      "Epoch 115/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5243 - val_loss: 0.5234\n",
      "Epoch 116/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5305 - val_loss: 0.5234\n",
      "Epoch 117/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5261 - val_loss: 0.5234\n",
      "Epoch 118/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5244 - val_loss: 0.5234\n",
      "Epoch 119/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5317 - val_loss: 0.5234\n",
      "Epoch 120/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5257 - val_loss: 0.5234\n",
      "Epoch 121/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.5234\n",
      "Epoch 122/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5297 - val_loss: 0.5234\n",
      "Epoch 123/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5243 - val_loss: 0.5234\n",
      "Epoch 124/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.5234\n",
      "Epoch 125/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5313 - val_loss: 0.5233\n",
      "Epoch 126/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.5233\n",
      "Epoch 127/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5305 - val_loss: 0.5233\n",
      "Epoch 128/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5307 - val_loss: 0.5233\n",
      "Epoch 129/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5322 - val_loss: 0.5233\n",
      "Epoch 130/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.5233\n",
      "Epoch 131/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5302 - val_loss: 0.5233\n",
      "Epoch 132/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5295 - val_loss: 0.5233\n",
      "Epoch 133/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.5233\n",
      "Epoch 134/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5238 - val_loss: 0.5233\n",
      "Epoch 135/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5290 - val_loss: 0.5233\n",
      "Epoch 136/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5340 - val_loss: 0.5233\n",
      "Epoch 137/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5244 - val_loss: 0.5233\n",
      "Epoch 138/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5250 - val_loss: 0.5233\n",
      "Epoch 139/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5249 - val_loss: 0.5233\n",
      "Epoch 140/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5252 - val_loss: 0.5233\n",
      "Epoch 141/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5276 - val_loss: 0.5233\n",
      "Epoch 142/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5219 - val_loss: 0.5232\n",
      "Epoch 143/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5283 - val_loss: 0.5232\n",
      "Epoch 144/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5259 - val_loss: 0.5232\n",
      "Epoch 145/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5268 - val_loss: 0.5232\n",
      "Epoch 146/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5283 - val_loss: 0.5232\n",
      "Epoch 147/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5322 - val_loss: 0.5232\n",
      "Epoch 148/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5352 - val_loss: 0.5232\n",
      "Epoch 149/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5319 - val_loss: 0.5232\n",
      "Epoch 150/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5276 - val_loss: 0.5232\n",
      "Epoch 151/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5280 - val_loss: 0.5232\n",
      "Epoch 152/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5274 - val_loss: 0.5232\n",
      "Epoch 153/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5266 - val_loss: 0.5232\n",
      "Epoch 154/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5306 - val_loss: 0.5232\n",
      "Epoch 155/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5248 - val_loss: 0.5232\n",
      "Epoch 156/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5267 - val_loss: 0.5232\n",
      "Epoch 157/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5260 - val_loss: 0.5232\n",
      "Epoch 158/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5306 - val_loss: 0.5232\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5260 - val_loss: 0.5232\n",
      "Epoch 160/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5261 - val_loss: 0.5232\n",
      "Epoch 161/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5274 - val_loss: 0.5232\n",
      "Epoch 162/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5317 - val_loss: 0.5232\n",
      "Epoch 163/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5344 - val_loss: 0.5232\n",
      "Epoch 164/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5294 - val_loss: 0.5232\n",
      "Epoch 165/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5309 - val_loss: 0.5232\n",
      "Epoch 166/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5247 - val_loss: 0.5232\n",
      "Epoch 167/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5311 - val_loss: 0.5231\n",
      "Epoch 168/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5270 - val_loss: 0.5231\n",
      "Epoch 169/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5383 - val_loss: 0.5232\n",
      "Epoch 170/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5253 - val_loss: 0.5231\n",
      "Epoch 171/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5337 - val_loss: 0.5231\n",
      "Epoch 172/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5279 - val_loss: 0.5231\n",
      "Epoch 173/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5307 - val_loss: 0.5231\n",
      "Epoch 174/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5280 - val_loss: 0.5231\n",
      "Epoch 175/1000\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.5260 - val_loss: 0.5231\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "feature = scaler.fit_transform(data[N_BASE])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, data[\"clade\"],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    shuffle= True)\n",
    "\n",
    "enc_dim = 2\n",
    "inp = Input(shape=(x_train.shape[1], ))\n",
    "encode = Dense(enc_dim, activation='linear')(inp)\n",
    "decode = Dense(x_train.shape[1], activation='linear')(encode)\n",
    "\n",
    "AE = Model(inp, decode)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=3),\n",
    "    # ModelCheckpoint(model_path, save_best_only=True)\n",
    "]\n",
    "\n",
    "AE.compile(loss=keras.losses.mean_squared_error, optimizer='sgd')\n",
    "\n",
    "hist = AE.fit(x_train, x_train,\n",
    "        epochs=1000,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        validation_data=(x_test, x_test),\n",
    "        callbacks=callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "according-england",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aggregate-remains",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2530967, 1.2840885], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE_W = AE.layers[1].get_weights()[0]\n",
    "np.linalg.norm(AE_W, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "characteristic-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_W /= np.linalg.norm(AE_W, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "coral-oasis",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1024,2) and (26148,1024) not aligned: 2 (dim 1) != 26148 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-22b1998fb0f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mae_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mae_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAE_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1024,2) and (26148,1024) not aligned: 2 (dim 1) != 26148 (dim 0)"
     ]
    }
   ],
   "source": [
    "ae_x, ae_y = np.dot(AE_W.T, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "distant-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25407272, -0.22816175, -0.3861854 , ..., -0.20524237,\n",
       "        -0.27494942, -0.18650754],\n",
       "       [-0.31540705, -0.31263257, -0.44133598, ..., -0.19925209,\n",
       "        -0.24083293, -0.19518129],\n",
       "       [-0.38546408,  0.68767586, -0.48071255, ...,  0.13601355,\n",
       "         0.17868063,  0.05723592],\n",
       "       ...,\n",
       "       [ 0.45269522,  0.31345392,  1.43664631, ...,  1.19848044,\n",
       "         1.45635518,  0.89408844],\n",
       "       [-0.29497758, -0.34580174, -0.4040626 , ..., -0.16007755,\n",
       "        -0.14931484, -0.09746432],\n",
       "       [-0.31200979, -0.33076505, -0.3825048 , ..., -0.27741101,\n",
       "        -0.29217467, -0.27357446]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new = np.hstack((x_test[:, :1000], x_test[:, :1000]))\n",
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "steady-earth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.02366648, -0.01034197],\n",
       "        [ 0.04764552,  0.02749572],\n",
       "        [ 0.08435544,  0.02646278],\n",
       "        ...,\n",
       "        [ 0.01854486, -0.03659267],\n",
       "        [ 0.03075085, -0.03743325],\n",
       "        [-0.01352394,  0.03566866]], dtype=float32),\n",
       " array([ 0.00023886, -0.00136205], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-combat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
